{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_json_files(folder_path):\n",
    "    data = []\n",
    "    for folder_name in os.listdir(folder_path):\n",
    "        folder_full_path = os.path.join(folder_path, folder_name)\n",
    "        if os.path.isdir(folder_full_path):\n",
    "            files = os.listdir(folder_full_path)\n",
    "            for file_name in files:\n",
    "                if file_name.endswith('.json'):\n",
    "                    file_path = os.path.join(folder_full_path, file_name)\n",
    "                    folder_split= folder_name.split(\"_\")    \n",
    "\n",
    "                    dataset = {\n",
    "                        'model' : folder_split[0],\n",
    "                        'threshold' : folder_split[-1],\n",
    "                        'finetune' :  folder_split[2],\n",
    "                        'dataset' : file_name.replace(\"_results.json\" , \"\"),\n",
    "                        'results' : None\n",
    "                    }\n",
    "\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        dataset['results'] = json.load(f)\n",
    "\n",
    "                    data.append(dataset)\n",
    "    return data\n",
    "\n",
    "# Load all JSON files in the 'res' folder\n",
    "folder_path = './results/'\n",
    "data = load_json_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "def calculate_mean(data,key,mkey):\n",
    "    m= []\n",
    "    for item in data:\n",
    "        if item['metrics'][key][mkey] is None or np.isnan(item['metrics'][key][mkey]):\n",
    "            continue\n",
    "        m.append(item['metrics'][key][mkey])\n",
    "    if len(m) == 0:\n",
    "        return None\n",
    "    \n",
    "    m = np.asarray(m)\n",
    "    m = m.sum() / len(m)\n",
    "    return float(round(m,2))\n",
    "\n",
    "def calculate_variance(data, key, mkey):\n",
    "    values = []\n",
    "    for item in data:\n",
    "        if item['metrics'][key][mkey] is None or np.isnan(item['metrics'][key][mkey]):\n",
    "            continue\n",
    "        values.append(item['metrics'][key][mkey])\n",
    "    if len(values) == 0:\n",
    "        return None\n",
    "    \n",
    "    values = np.asarray(values)\n",
    "    variance = np.var(values)\n",
    "    return float(round(variance, 2))\n",
    "\n",
    "def calculate_median(data, key, mkey):\n",
    "    values = []\n",
    "    for item in data:\n",
    "        if item['metrics'][key][mkey] is None or np.isnan(item['metrics'][key][mkey]):\n",
    "            continue\n",
    "        values.append(item['metrics'][key][mkey])\n",
    "    if len(values) == 0:\n",
    "        return None\n",
    "    \n",
    "    values = np.asarray(values)\n",
    "    median = np.median(values)\n",
    "    return float(round(median, 2))\n",
    "\n",
    "def calculate_std_dev(data, key, mkey):\n",
    "    values = []\n",
    "    for item in data:\n",
    "        if item['metrics'][key][mkey] is None or np.isnan(item['metrics'][key][mkey]):\n",
    "            continue\n",
    "        values.append(item['metrics'][key][mkey])\n",
    "    if len(values) == 0:\n",
    "        return None\n",
    "    \n",
    "    values = np.asarray(values)\n",
    "    std_dev = np.std(values)\n",
    "    return float(round(std_dev, 2))\n",
    "\n",
    "\n",
    "def get_best(data,key,mkey, limit = 3):\n",
    "    best = []\n",
    "    for item in data:\n",
    "        if item['metrics'][key][mkey] is None or np.isnan(item['metrics'][key][mkey]):\n",
    "            continue\n",
    "\n",
    "        best.append(\n",
    "            {\n",
    "                'filename': item['filename'],\n",
    "                'path' : item['path'],\n",
    "                'value': item['metrics'][key][mkey]\n",
    "            }\n",
    "        )\n",
    "    if len(best) == 0:\n",
    "        return None\n",
    "    \n",
    "    best = np.asarray(best)\n",
    "    best = sorted(best, key=lambda x: x['value'])\n",
    "    return best[-limit:], best[:-limit]\n",
    "\n",
    "\n",
    "data_process = []\n",
    "for d in data:\n",
    "    # get list of all keys resulst\n",
    "    sal_keys = list(d['results'][0]['metrics'].keys())\n",
    "    for key in sal_keys:\n",
    "        result= {\n",
    "            'model' : d['model'],\n",
    "            'dataset' : d['dataset'],\n",
    "            'threshold' : d['threshold'],\n",
    "            'finetune' : d['finetune'],\n",
    "            'key' : key,\n",
    "            'metrics' :  {},\n",
    "            'statistics': {},\n",
    "            'bests' : {},\n",
    "            'worsts' : {}\n",
    "        }   \n",
    "\n",
    "        metrics_keys = list(d['results'][0]['metrics'][key].keys())\n",
    "        for mkey in metrics_keys:\n",
    "            if mkey== \"statistics\":\n",
    "                continue\n",
    "            mean__ = calculate_mean(d['results'],key,mkey)\n",
    "            if mean__ is None:\n",
    "                continue\n",
    "            result['metrics'][mkey] = mean__\n",
    "            bests, worts = get_best(d['results'],key,mkey)\n",
    "\n",
    "            result['bests'][mkey] = bests\n",
    "            result['worsts'][mkey] = worts\n",
    "\n",
    "            result['statistics'][mkey] = {\n",
    "                'variance' : calculate_variance(d['results'],key,mkey),\n",
    "                'median' : calculate_median(d['results'],key,mkey),\n",
    "                'std_dev' : calculate_std_dev(d['results'],key,mkey)\n",
    "            }  \n",
    "\n",
    "        data_process.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_by_dataset(data):\n",
    "    groups = {}\n",
    "    for d in data:\n",
    "        dataset = d['dataset']\n",
    "        if dataset not in groups:\n",
    "            groups[dataset] = []\n",
    "        groups[dataset].append(d)\n",
    "    return groups\n",
    "\n",
    "def groups_by_model(data):\n",
    "    groups = {}\n",
    "    for d in data:\n",
    "        model = d['model']\n",
    "        if model not in groups:\n",
    "            groups[model] = []\n",
    "        groups[model].append(d)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: p3_orientations\n",
      "TranSalNetDense\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.73, 'msrb': 1.66}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 0.94, 'msrb': 1.63}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.87, 'msrb': 1.65}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 0.55, 'msrb': 2.27}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.93, 'msrb': 2.89}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.91, 'msrb': 1.75}\n",
      "\n",
      "Unisal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.14, 'msrb': 48.75}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 2.21, 'msrb': 1.02}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.82, 'msrb': 1.3}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 1.12, 'msrb': 1.12}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.41, 'msrb': 40.64}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.82, 'msrb': 1.33}\n",
      "\n",
      "TempSal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.44, 'msrb': 131.77}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 0.75, 'msrb': 1.43}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.79, 'msrb': 1.63}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.79, 'msrb': 26.49}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.82, 'msrb': 1.53}\n",
      "\n",
      "DATASET: p3_sizes\n",
      "TranSalNetDense\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.7, 'msrb': 2.08}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 0.86, 'msrb': 1.58}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.85, 'msrb': 1.78}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 0.55, 'msrb': 2.5}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.85, 'msrb': 3.39}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.87, 'msrb': 1.74}\n",
      "\n",
      "Unisal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.13, 'msrb': 40.24}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 1.48, 'msrb': 1.09}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.72, 'msrb': 1.47}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 1.02, 'msrb': 1.17}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.26, 'msrb': 52.81}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.69, 'msrb': 1.58}\n",
      "\n",
      "TempSal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.52, 'msrb': 44.27}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 0.59, 'msrb': 1.85}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 0.71, 'msrb': 1.85}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 0.64, 'msrb': 24.35}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 0.73, 'msrb': 1.75}\n",
      "\n",
      "DATASET: p3_colors\n",
      "TranSalNetDense\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.8, 'msrb': 1.71}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 1.46, 'msrb': 1.18}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 1.19, 'msrb': 1.33}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 0.6, 'msrb': 1.96}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 1.76, 'msrb': 2.09}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 1.36, 'msrb': 1.26}\n",
      "\n",
      "Unisal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 0.3, 'msrb': 20.98}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 3.98, 'msrb': 0.9}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 1.1, 'msrb': 1.05}\n",
      "Th: 0.5 | Key: saliency_Sub | {'msrt': 0.92, 'msrb': 1.22}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 2.47, 'msrb': 12.26}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 1.14, 'msrb': 1.05}\n",
      "\n",
      "TempSal\n",
      "Th: 0.5 | Key: saliency | {'msrt': 1.7, 'msrb': 4.09}\n",
      "Th: 0.5 | Key: rarity | {'msrt': 1.39, 'msrb': 0.98}\n",
      "Th: 0.5 | Key: saliency_Add | {'msrt': 2.02, 'msrb': 0.98}\n",
      "Th: 0.5 | Key: saliency_Prod | {'msrt': 6.28, 'msrb': 2.43}\n",
      "Th: 0.5 | Key: saliency_Itti | {'msrt': 2.05, 'msrb': 0.97}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_data = groups_by_dataset(data_process)\n",
    "\n",
    "for dataset, dataset_values in datasets_data.items():\n",
    "    # grousp by models\n",
    "    models_data = groups_by_model(dataset_values)\n",
    "\n",
    "\n",
    "    if \"p3\" not in dataset:\n",
    "        continue\n",
    "\n",
    "    print(f\"DATASET: {dataset}\")\n",
    "\n",
    "    for model, model_values in models_data.items():\n",
    "        model_values.sort(key=lambda x: x['threshold'])\n",
    "\n",
    "        if model == \"TranSalNetRes\":\n",
    "            continue\n",
    "\n",
    "        print(f\"{model}\")\n",
    "\n",
    "\n",
    "        for item in model_values:\n",
    "            #  filter threshold\n",
    "            if item['threshold'] != \"0.5\":\n",
    "                continue\n",
    "\n",
    "            # filter map\n",
    "            # if item['key'] != \"saliency\" and item['key'] != \"saliency_Add\" and item['key'] != \"rarity\":\n",
    "                continue\n",
    "\n",
    "            print(f\"Th: {item['threshold']} | Key: {item['key']} | {item['metrics']}\")\n",
    "            # print(f\"     - statistics: {item['statistics']}\")\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoRe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
